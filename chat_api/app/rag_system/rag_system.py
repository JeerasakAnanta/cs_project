import os
import logging

# loding environment variable
from dotenv import load_dotenv

# langchain
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_openai import OpenAIEmbeddings

# vecter database
from langchain_qdrant import QdrantVectorStore
from pydantic import BaseModel
from qdrant_client import QdrantClient

# loding environment variable
from dotenv import load_dotenv

# FastAPI
from fastapi import FastAPI
from fastapi import APIRouter
from fastapi.middleware.cors import CORSMiddleware

# langchain
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_openai import OpenAIEmbeddings

# vecter database
from langchain_qdrant import QdrantVectorStore
from qdrant_client import QdrantClient

# loading environment variable
from app.utils.config import OPENAI_API_KEY, QDRANT_URL, COLLECTION_NAME 


def create_chatbot_chain() -> ConversationalRetrievalChain:
    """
    Create a ConversationalRetrievalChain with a custom prompt.
    """

    # Define the prompt template
    prompt = PromptTemplate(
        input_variables=["context", "question"],
        template="""
            à¸„à¸¸à¸“à¸„à¸·à¸­ LannaFinChat à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸­à¸±à¸ˆà¸‰à¸£à¸´à¸¢à¸°à¸‚à¸­à¸‡à¸¡à¸«à¸²à¸§à¸´à¸—à¸¢à¸²à¸¥à¸±à¸¢à¹€à¸—à¸„à¹‚à¸™à¹‚à¸¥à¸¢à¸µà¸£à¸²à¸Šà¸¡à¸‡à¸„à¸¥à¸¥à¹‰à¸²à¸™à¸™à¸²  
            à¸„à¸§à¸²à¸¡à¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸„à¸·à¸­ **à¸à¸²à¸£à¹ƒà¸«à¹‰à¸„à¸³à¸›à¸£à¸¶à¸à¸©à¸²à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š "à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸›à¸à¸´à¸šà¸±à¸•à¸´à¸‡à¸²à¸™à¸”à¹‰à¸²à¸™à¸à¸²à¸£à¹€à¸‡à¸´à¸™à¹à¸¥à¸°à¸à¸²à¸£à¹€à¸šà¸´à¸à¸ˆà¹ˆà¸²à¸¢à¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢à¹ƒà¸™à¸à¸²à¸£à¸”à¸³à¹€à¸™à¸´à¸™à¸‡à¸²à¸™"**  
            à¹‚à¸”à¸¢à¸„à¸£à¸­à¸šà¸„à¸¥à¸¸à¸¡à¸«à¸±à¸§à¸‚à¹‰à¸­à¸•à¹ˆà¸²à¸‡ à¹† à¹€à¸Šà¹ˆà¸™:  
            - à¸à¸²à¸£à¹€à¸šà¸´à¸à¸„à¹ˆà¸²à¹ƒà¸Šà¹‰à¸ˆà¹ˆà¸²à¸¢à¹ƒà¸™à¸à¸²à¸£à¹€à¸”à¸´à¸™à¸—à¸²à¸‡à¹„à¸›à¸£à¸²à¸Šà¸à¸²à¸£    

            à¸à¸£à¸¸à¸“à¸²à¸›à¸à¸´à¸šà¸±à¸•à¸´à¸•à¸²à¸¡à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚à¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰à¹ƒà¸™à¸à¸²à¸£à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡:

            - à¹ƒà¸Šà¹‰ **à¸ à¸²à¸©à¸²à¹„à¸—à¸¢** à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™  
            - à¸•à¸­à¸šà¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š **Markdown**  
            - à¹ƒà¸«à¹‰à¸„à¸³à¸•à¸­à¸šà¸—à¸µà¹ˆ **à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¸¥à¸°à¹€à¸­à¸µà¸¢à¸” à¹à¸¥à¸°à¹€à¸›à¹‡à¸™à¸¥à¸³à¸”à¸±à¸šà¸‚à¸±à¹‰à¸™à¸•à¸­à¸™**  
            - à¸«à¸²à¸à¸ˆà¸³à¹€à¸›à¹‡à¸™à¹ƒà¸«à¹‰à¸ªà¸£à¸¸à¸›à¹€à¸›à¹‡à¸™ **à¸•à¸²à¸£à¸²à¸‡ Markdown**  
            - à¸«à¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸„à¸³à¸–à¸²à¸¡à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­ à¹ƒà¸«à¹‰à¸•à¸­à¸šà¸§à¹ˆà¸²  
            > `"LannaFinChat à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸«à¸²à¸„à¸³à¸•à¸­à¸šà¸ˆà¸²à¸à¹€à¸­à¸à¸ªà¸²à¸£à¹„à¸”à¹‰à¸„à¸£à¸±à¸š"`  
            - à¹ƒà¸Šà¹‰à¸„à¸³à¸¥à¸‡à¸—à¹‰à¸²à¸¢ "**à¸„à¸£à¸±à¸š**" à¸«à¸£à¸·à¸­ "**à¹„à¸¡à¹ˆà¸„à¸£à¸±à¸š**"  
            - à¸—à¸¸à¸à¸„à¸³à¸•à¸­à¸šà¸•à¹‰à¸­à¸‡à¸¡à¸µ **à¸­à¸²à¸£à¸¡à¸“à¹Œ à¸„à¸§à¸²à¸¡à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£ à¹à¸¥à¸°à¸ªà¸¸à¸ à¸²à¸ž** à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸œà¸¹à¹‰à¸­à¹ˆà¸²à¸™à¸£à¸¹à¹‰à¸ªà¸¶à¸à¸”à¸µà¸„à¸£à¸±à¸š  

            > à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¸‚à¸¶à¹‰à¸™à¸•à¹‰à¸™à¸„à¸³à¸•à¸­à¸š:  
            > à¸ªà¸§à¸±à¸ªà¸”à¸µà¸„à¸£à¸±à¸š ðŸ˜Š LannaFinChat à¸‚à¸­à¸­à¸˜à¸´à¸šà¸²à¸¢à¸‚à¸±à¹‰à¸™à¸•à¸­à¸™ à¸”à¸±à¸‡à¸™à¸µà¹‰à¸•à¹ˆà¸­à¹„à¸›à¸„à¸£à¸±à¸š...

            Context:
            
        {context}
        à¸„à¸³à¸–à¸²à¸¡à¸•à¹‰à¸™à¸‰à¸šà¸±à¸š: {question}
        """,
    )

    # Initialize the embeddings
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-large",
    )

    # Create the Qdrant client and vector store
    qdrant_client = QdrantClient(QDRANT_URL)
    qdrant_store = QdrantVectorStore(
        client=qdrant_client,
        collection_name=COLLECTION_NAME,
        embedding=embeddings,
    )

    # Create the ConversationalRetrievalChain
    return ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(
            model="gpt-4o-mini",
        ),
        retriever=qdrant_store.as_retriever(
            search_type="similarity", search_kwargs={"k": 10, "score_threshold": 0.5}
        ),
        combine_docs_chain_kwargs={"prompt": prompt},
        return_source_documents=False,
    )


# Store for chat history
chat_history: list[tuple[str, str]] = []


def chatbot(user_massage: str) -> str:
    """
    API for chatbot interaction.
    Receives user query and responds with chatbot-generated answer.
    """

    chain = create_chatbot_chain()

    result = chain.invoke({"question": user_massage, "chat_history": chat_history})

    chat_history.append((user_massage, result["answer"]))

    # Source document handling
    source_document = (
        result["source_documents"][0].metadata.get("source", None)
        if "source_documents" in result and len(result["source_documents"]) > 0
        else None
    )
    source_document_page = (
        result["source_documents"][0].metadata.get("page", None)
        if source_document
        else None
    )

    return {
        "message": result["answer"]
    }
